Rank Word Embeddings Fairness using several Metrics and Queries
###############################################################

The following code replicates the execution of the paper's case study: 

P. Badilla, F. Bravo-Marquez, and J. PÃ©rez 
WEFE: The Word Embeddings Fairness Evaluation Framework In Proceedings of the
29th International Joint Conference on Artificial Intelligence and the 17th 
Pacific Rim International Conference on Artificial Intelligence (IJCAI-PRICAI 2020), Yokohama, Japan. 


In this study, the authors evaluate:

- Multiple queries grouped under different criteria (gender, ethnicity, religion)
- Multiple embeddings (:code:`word2vec-google-news`, :code:`glove-wikipedia`, 
  :code:`glove-twitter`, :code:`conceptnet`, :code:`lexvec`, 
  :code:`fasttext-wiki-news`)
- Multiple metrics (:code:`WEAT` and its variant, :code:`WEAT effect size`, 
  :code:`RND`, :code:`RNSB`). 

From the results grouped by query criteria, rankings of the bias that was 
detected in each embedding model are generated by metric and plotted. 
An overall is included, which is simply the sum of all the rankings by 
model and by metric.

Finally, the matrix of correlations between these rankings is calculated and 
plotted.

The code of this experiment is relatively long, as is the time of its execution.
You can see (an even) partial implementation in a Jupyter Notebook using the 
following `link <https://github.com/dccuchile/wefe/blob/master/examples/WEFE_rankings.ipynb>`_.
